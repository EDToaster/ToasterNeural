package neural;

import util.exception.NeuralNetworkLayerNumberException;
import util.exception.NeuralNetworkMatrixSizeException;
import util.math.Matrix;
import util.tools.PredictionSet;

import java.io.Serializable;
import java.util.Random;

import static util.tools.Values.*;

public class ToasterNeural implements Serializable {

    private Matrix[] cWeights; //connector weights
    private Matrix[] nBiases; // node biases
    private int layers;
    private int inputs;
    private int outputs;
    private double learningRate;


    public ToasterNeural(double learningRate, Random r, int... nodes) {

        if (nodes.length < 2) {
            throw new NeuralNetworkLayerNumberException(TOO_FEW_LAYERS_EXCEPTION_MESSAGE);
        }

        if (r == null) r = new Random();
        this.learningRate = learningRate;

        cWeights = new Matrix[nodes.length - 1];
        nBiases = new Matrix[nodes.length - 1];
        layers = nodes.length;
        inputs = nodes[0];
        outputs = nodes[nodes.length - 1];

        for (int i = 0; i < nodes.length - 1; i++) {
            int in = nodes[i];
            int out = nodes[i + 1];

            Matrix connectors = new Matrix(out, in, r);
            Matrix bias = new Matrix(out, 1, r);
            cWeights[i] = connectors;
            nBiases[i] = bias;
        }
    }

    public ToasterNeural(int... nodes) {
        this(DEFAULT_LEARNING_RATE, null, nodes);
    }

    public PredictionSet predict(Matrix input) {
        if (input.m() != cWeights[0].n())
            throw new NeuralNetworkMatrixSizeException(INPUT_VECTOR_LENGTH_EXCEPTION_MESSAGE);

        Matrix curr = input;
        PredictionSet set = new PredictionSet();
        set.add(curr);

        for (int i = 0; i < cWeights.length; i++) {
            curr = curr.mult(cWeights[i]).add(nBiases[i]).map(sigmoid.f);
            set.add(curr);
            assert curr.isVector();
        }

        return set;
    }

    public PredictionSet predict(double in) {
        return predict(new Matrix(new double[][]{{in}}));
    }

    public void train(Matrix input, Matrix target) {
        //TODO: VERIFY

        if (target.m() != cWeights[cWeights.length - 1].m())
            throw new NeuralNetworkMatrixSizeException(TARGET_VECTOR_LENGTH_EXCEPTION_MESSAGE);


        PredictionSet result = predict(input);
        Matrix[] reversedLayers = result.getInvertedLayers();

        Matrix lastErrors = null;

        for (int i = 0; i < reversedLayers.length - 1; i++) {

            Matrix prevLayerTransposed = reversedLayers[i + 1].transpose();
            Matrix layer = reversedLayers[i];

            Matrix transitionLayer = cWeights[cWeights.length - i - 1];
            // feed forward matrix transforms previous layer to this layer.
            Matrix errors = null;

            if (i == 0) {
                errors = target.sub(layer);
            } else {
                Matrix prev = cWeights[cWeights.length - i];
                errors = lastErrors.mult(prev.transpose());
            }

            lastErrors = errors;

            Matrix gradients = layer.map(sigmoid.df).hadamard(errors).mult(learningRate);

            Matrix transitionDeltas = prevLayerTransposed.mult(gradients);

            cWeights[cWeights.length - i - 1] = transitionLayer.add(transitionDeltas);
            nBiases[nBiases.length - i - 1] = nBiases[nBiases.length - i - 1].add(gradients);

        }
    }

    public void train(double in, double out) {
        train(new Matrix(new double[][]{{in}}), new Matrix(new double[][]{{out}}));
    }

    public Matrix[] getWeights() {
        return cWeights;
    }

    public Matrix[] getBiases() {
        return nBiases;
    }

    public int getLayers() {
        return layers;
    }

    public int getInputs() {
        return inputs;
    }

    public int getOutputs() {
        return outputs;
    }

    public void printWeights() {
        for (Matrix cWeight : cWeights) {
            System.out.printf("-----%dÃ—%d%s", cWeight.m(), cWeight.n(), System.lineSeparator());
            cWeight.print();
        }
        System.out.println("-----");
    }


    public static final ActivatorFunction sigmoid = new ActivatorFunction(
            (x -> 1.0 / (1.0 + Math.exp(-x))),    // f
            (y -> y * (1 - y))                    // df
    );


    public interface Func {
        double apply(double in);
    }

    public static class ActivatorFunction {
        public Func f, df;

        public ActivatorFunction(Func f, Func df) {
            this.f = f;
            this.df = df;
        }
    }
}
